# Journal — 9-20-2025

## 1) What I learned (bullets, not prose)
- The Docker setup took a month
- When you present, talk in pipelines (ingest - store - present), focus on something unique (to understand tradeoffs), share data mapping, create a documentation
- Process: sandbox > dlt > mart (bronze > silver > gold)
- TABLE creates and saves the data like a copy; VIEW is continuously query (saves query rather than table)
- DBEAVER allows us to view the process of the whole pipeline
- Where to input SQL: think of the scope (is it changeable, permanent, etc)
- ENGINE = only saves data for a while (disappears when you shut down the tool)
- YAML is used to configure (key-value pair)
- DBT have an automatic fucntion to understand which should go first based on dependencies
- SQL started from a relational theory
- Normalization is part of the design phase
- In the table, everything should reference to just one key

### Remote Setup
**DLT**
- Dbeaver: Connect to remote server 54.87.106.52
- Change compose.yaml to DESTINATION__CLICKHOUSE__CREDENTIALS__HOST:       "54.87.106.52"
- Change 01-dlt-mpg-pipeline.py to @dlt.resource(name="cars_jess")
**DBT**
- Change Clean to mpg_standardized to mpg_standardized_jess
- Change mart cylinders to mpg_standardized_jes
- Change profiles.yml to autompg___cars_jess

## 2) New vocabulary (define in your own words)
- YAML: Yet Another Markdown Language
- Schema: model of data relations
- Primary Key is the unique id
- Foreign Key id to create relationships
- Kimbull Bus Matrix illustration of possible data that may be encountered
- 1NF atomicity, safety check in cell levels
- 2NF prevents unconnected data to be in one table
- 3NF prevents non-key attributes to depend on other non-key attributes

## 3) Data Engineering mindset applied (what principles did I use?)
- Raw stays raw!
- Reproducible

## 4) Decisions & assumptions (why, alternatives, trade-offs)
- In order to catch up with the pace of the lecture, I skipped playing around with the SQL codes and fully relied on what was shared on the lecture.

## 5) Open questions (things I still don’t get)
- When do we use VIEW and TABLE?
      - Use a table when you need to persist data.
      - Use a view when you need a reusable lens/query on top of existing tables.
- How does python codes connect with SQL code? https://chatgpt.com/c/68c76e11-942c-832e-9446-4ffb498d978e
      - Python = flexible for ingestion from outside.
      - SQL = powerful and declarative for cleaning & modeling inside the database.
- How is the remote server code/host built? https://chatgpt.com/c/68d280ba-b8b8-832e-ae5e-d990f4eddb4f

## 6) Next actions (small, doable steps)
- [ ] docker codes
- [ ] datacamp

## 7) Artifacts & links (code, queries, dashboards)
- How Local Setup Works: https://github.com/ogbinar/ftw-de-bootcamp/blob/main/TECHNICAL-README.md
- G6 Data Dictionary:  https://docs.google.com/spreadsheets/d/1jEI_H3qTLBcVmzg4Vni8EP0Bflqj9eGhY9i2PUqZQZA/edit?gid=0#gid=0 
- Lecture File: https://classroom.google.com/u/0/c/ODAyMjYwODE2ODE2/m/ODA3ODcxOTY3MzIw/details

---

### Mini reflection (3–5 sentences)
It is alright to make mistakes. Good money in Docker. Finally realized that INNER JOIN is to match all rows while LEFT JOIN is about outputting all rows in the left table despite there being no matching values.

It was surprising to me how schemas are built manually. When I used to do PowerBI, it is all about just finding the keys that connects the Fact Table to the Dimension Tables then the rest is handled by the program itself. It is crazy to see how it built manually.


### BONUS: What is a meme that best describes what you feel or your learning today?

![Alt text](..assets/3ecbeeca-11a3-43ec-af39-017b59a460a7_500x500.jpg)

