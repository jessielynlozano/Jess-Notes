# Journal — 10-11-2025

## 1) What I learned (bullets, not prose)
- Data Lifecycle: Collection > Storage > Transformation > Serving > Visualization/Decision
- Flow: Source > Transport > Landing > Staging > Modeled > Serving
- JSON works in key-value pairs. Example "id":1, "student":Ana
- YML uses syntax, indention. Uses key-value pair as well.
- uv in python allows us to isolate the changes in the directory only. For example, the dependencies can only occur in the directory
- Dataframe is essentially tabular while series is a list
- Particular project use pandas, but if you want to connect to systems use Ibis
- Web scraping/web harvesting/web data extraction is data scraping used for extracting data from website.
- How website works: There is a server containing files like home page then Google comes in asking for a page then the server shares an HTML version of the file.
- JavaScript makes the website dynamic.

## 2) New vocabulary (define in your own words)
- XML: Extensible Markup Language -  you can create various data types
- API: Application Programming Interface
- Abstraction: we do not need to know the underlying codes that make it work, like an umbrella code containing other mini codes

## 3) Data Engineering mindset applied (what principles did I use?)
- 

## 4) Decisions & assumptions (why, alternatives, trade-offs)
- 

## 5) Open questions (things I still don’t get)
- How to do data checking using dbt?
- How can I print the 03-api.py in tabular form instead of JSON?

## 6) Next actions (small, doable steps)
- [ ] 

## 7) Artifacts & links (code, queries, dashboards)
- 

---

### Mini reflection (3–5 sentences)
There is no one sure way to do do things.
Building things to last.

### BONUS: What is a meme that best describes what you feel or your learning today?

![Alt text](https://file.forms.app/sitefile/d-s-m-3.jpeg)
